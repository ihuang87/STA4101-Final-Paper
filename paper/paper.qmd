---
title: "Explaining Box Office with Minimal Information"
subtitle: "Can a Movie’s Success Be Explained by Basic Metadata?"
author: 
  - Isabelle Huang

date: today
date-format: long
abstract: "Movie box office performance is an important topic in both industry and academic research, informing investment decisions, marketing strategy, and our understanding of audience behaviour. This study examines how well simple movie attributes can explain box office outcomes without relying on complex models. Using a dataset of 6,897 films released between 2006 and 2015, we fit linear regression and mixture-of-regressions models to explain box office performance using only genre, distributor, MPAA rating, release time, and a small set of title-based indicators. Our best model achieves an $R^2$ of 0.68, suggesting that basic metadata captures much of the variation in the data but is not sufficient for accurate explanation. Richer information such as budget, marketing, franchise status, and word-of-mouth effects is likely essential for more accurate analysis."

format: 
    pdf:
        toc: true
        number-sections: true
        fig-align: center

bibliography: references.bib
---
\newpage
# Introduction

Movie theatres are a common destination for families and friends to gather and briefly escape from daily life at a relatively low cost. Yet thousands of films are released worldwide each year, and only a small fraction are widely watched or remembered. What determines which movies audiences choose? Prior work has studied determinants such as budget, sequels, star power, and reviews, and has used these variables to model or forecast revenue [@{Hao2023FactorsFilmRevenue, Scott2019ReturnRegressions}]. Many studies also apply machine learning methods to improve predictive performance [@{JangeZarateAragonEncarnacion2025SystematicReviewBoxOffice}]. This raises a natural question: how much of a movie’s box office can be explained using only easily available information and simple models? If strong performance is possible with minimal predictors, decisions could be made at lower cost, both in data collection and in analysis. In this project, we investigate the explanatory power of basic movie metadata under simple regression models.

We first fit a linear regression model to explain ticket sales using only genre, distributor, MPAA rating, release year and month, and a small set of indicator variables capturing whether the title contains certain frequent words. We then fit a mixture-of-regressions model to test whether a more flexible specification can substantially improve fit using the same limited feature set. Our main estimand is the log expected number of tickets sold for a movie with given basic attributes. Let $Y_i$ denote the log number of tickets sold for film $i$, and let $X_i$ denote its features. The target regression function is
$$ m(x) = \mathbb{E}[\,Y_i \mid X_i = x\,]$$

Overall, these simple variables explain box office outcomes to a meaningful extent, though not necessarily sufficient. After tuning, our best model achieves an $R^2$ of approximately 0.68, leaving roughly one-third of the variation in ticket sales unexplained. Among the predictors considered, genre has the strongest association with ticket sales, while title-based indicators contribute the least. Although the resulting models are not accurate enough for practical forecasting, they may serve as useful baselines and as intermediate proxies when richer covariates are unavailable. Future work could either extract more signal from limited data or incorporate additional predictors to capture more complex drivers of performance.

The remainder of this paper is organized as follows. Section 2 describes the dataset and cleaning procedures. Section 3 presents the modeling approach and empirical results. Section 4 discusses findings and limitations and outlines directions for future work.


# Data {#sec-data}

## Overview


We use the statistical programming language Python [@PythonSoftwareFoundationPython] together with the data library Pandas [@pandas-dev-pandas-2025] to clean and analyze our dataset. The data come from the Data and Story Library [@dasl_movies], an open-source repository of real-world datasets for teaching and practice. Our dataset contains 6,897 major films released between 2006 and 2015, with variables including title, genre, distributor, MPAA rating, release date, and gross revenue. 

## Outcome variables
There are two variables in the dataset that measure box office performance: gross revenue and the number of tickets sold. Gross revenue is an aggregate outcome that depends on realized attendance, ticket prices, and the length of the theatrical run, reported in USD. The number of tickets sold is an approximate count based on information provided by theatres and production companies. Because gross revenue can be derived from ticket sales, we focus our analysis on the number of tickets sold. Since this response is numeric, linear regression is a natural starting point.

However, ticket sales are highly right-skewed: a small number of blockbusters sell millions of tickets, while many films sell only a few thousand or fewer. The mean number of tickets sold is about 1.77 million, but the median is only 22,962, indicating that the mean is heavily influenced by a small set of extreme values. Consistent with this, the standard deviation is large at 5.45 million, reflecting substantial dispersion in ticket sales across films.

We visualize films with the highest and lowest ticket sales in the following graphs.

::: {#fig-top-bottom layout-ncol=2}

![](images/top_10_sold.png)

![](images/last_10_sold.png)

Ticket sales for the ten best- and worst-selling movies.
:::

Because of the strong clustering near zero, we work with a base-10 log transformation of tickets sold instead. This compresses the scale and reduces the influence of extreme values, producing a distribution that is more symmetric and closer to normal. The mean of log tickets sold is about 7.38, the median is about 10.0, and the standard deviation is about 2.87. The transformed distribution is still slightly bimodal, with one peak around 4 and another around 7.

![Number of tickets sold on the log base 10 scale](images/tickets_sold_log.png){#fig-transformed-tickets-sold fig-align="center" width=50%}

## Predictor variables
We treat all remaining variables in the dataset (excluding gross revenue) as potential predictors of ticket sales. Our primary predictors of interest are Genre and Distributor. Genre is a categorical variable describing the film’s primary genre such as Action and Comedy. In our sample, Comedy and Adventure are among the most popular genres in recent years, while Drama is the most frequently produced genre (Figure 3). Distributor is also categorical and identifies the company responsible for releasing the film to theatres. Between 2006 and 2015, IFC and Warner Bros appear most often in the dataset, with roughly 300 films each.

The remaining variables are expected to have weaker effects on box office performance, but we include them for a more complete picture. MPAA rating captures the film’s content rating (e.g., G, PG, PG-13, R). Release year and release month record when the film was released and may capture timing effects such as holiday-season boosts.

::: {#fig-top-bottom layout-ncol=2}

![](images/best_genre.png)

![](images/movies_of_genre.png)

The best selling genres and most produced genres of movies.
:::

In addition, we incorporate information from movie titles by extracting simple text-based features. We test whether including certain keywords in a title is associated with higher ticket sales, under the idea that recognizable or appealing words may attract audience attention. We identify the most frequent words appearing in titles—“man”, “love”, and “life”—and create three indicator variables for whether each word appears in a given title. These variables are then merged into the main dataset.

Rows with missing values were removed from the dataset prior to analysis, leaving 6,337 observations. The dataset is relatively well curated, so no further cleaning is required. That said, because this is an observational dataset of commercially released films, some measurement error may be present, for example, in approximate ticket counts or genre assignments. We treat the recorded values as given throughout.


# Model
Based on the exploratory analysis, it appears reasonable to model the base-10 log of tickets sold as a linear function of the predictors. In addition, motivated by the bimodal shape of the transformed distribution, we also fit a mixture-of-regressions model to test whether allowing two latent groups can better capture the data and improve model fit.

## Model set-up

## Linear regression model
To estimate the regression function $m(x)$ we first fit Linear Regression model for the logged tickets sold using Ordinary Least Square Estimators. For each movie $i \in \{1,\dots,n \}$, let

- $Y_i$ be logged number of tickets sold,
- $x_{i,\text{year}}$ and $x_{i,\text{month}}$ be release year and month of the movie,
- $G_i$, $D_i$, and $M_i$ denote the categorical variables Genre, Distributor, and MPAA rating,
- $z_{i,\text{man}}, z_{i,\text{love}}, z_{i,\text{life}} \in \{0,1\}$ be the three title indicators.

Then the full linear model can then be written as
$$
\begin{aligned}
Y_i &= \beta_0 + \beta_{1} x_{i,\text{year}} + \beta_{1} x_{i,\text{month}}\\
    &+ \sum_{g} \gamma_g \,\mathbb{1}\{G_i = g\} + \sum_{d} \delta_d \,\mathbb{1}\{D_i = d\}
+ \sum_{m} \eta_m \,\mathbb{1}\{M_i = m\}\\
    &+ \alpha_{\text{man}} z_{i,\text{man}} + \alpha_{\text{love}} z_{i,\text{love}} + \alpha_{\text{life}} z_{i,\text{life}} + \varepsilon_i
\end{aligned}
$$
We implement this model in Python using @SeaboldPerktold2010Statsmodels
 Linear Rregression makes several assumptions, including linearity, independence, homoscedasticity, and normality of errors and these assumptions are roughly satisfied in our case.

## Mixture Regression Models
We also consider a finite mixture and linear regression for $Y_i$ with the same predictors that we previously considered.
Let $Z_i \in \{1,2\}$ be an unobserved component indicator such that
$$
\Pr(Z_i = k) = \pi_k, \qquad k = 1,2,
$$
with $\pi_k > 0$ and $\pi_1 + \pi_2 = 1$.
Conditional on $Z_i = k$ we assume a standard linear regression model
$$
Y_i \mid (Z_i = k, \mathbf{X}_i) \sim
\mathcal{N}\!\big(\mathbf{X}_i^\top \boldsymbol{\beta}_k, \, \sigma_k^2\big),
\qquad k = 1,2,
$$
where $\boldsymbol{\beta}_k$ is the vector of regression coefficients
and $\sigma_k^2$ is the error variance for component $k$. So this allows us to model the relationship specific to the two groups of movies that we suspect exist in the data.

Marginally, the conditional density of $Y_i$ given $\mathbf{X}_i$ is
$$
f(y_i \mid \mathbf{X}_i, \boldsymbol{\theta})
= \sum_{k=1}^{2} \pi_k \,
  \phi\!\big(y_i \mid \mathbf{X}_i^\top \boldsymbol{\beta}_k, \sigma_k^2\big),
$$
where $\boldsymbol{\theta} = (\pi_1,\pi_2,\boldsymbol{\beta}_1,\boldsymbol{\beta}_2, \sigma_1^2,\sigma_2^2)$ and $\phi(\cdot \mid \mu,\sigma^2)$ denotes the univariate Normal distribution.
The observed-data likelihood for $\boldsymbol{\theta}$ is therefore
$$
L(\boldsymbol{\theta} \mid \{y_i,\mathbf{X}_i\}_{i=1}^n)
= \prod_{i=1}^{n}
  \left\{
    \sum_{k=1}^{2} \pi_k \,
    \phi\!\big(y_i \mid \mathbf{X}_i^\top \boldsymbol{\beta}_k, \sigma_k^2\big)
  \right\},
$$
and can be maximised using an expectation–maximization (EM) algorithm which is built in to the gmm model provided by ScikitLearn [@PedregosaEtAl2011ScikitLearn].


## Model justification
As discussed earlier, our response variable is numeric, making linear regression a natural starting point. Linear regression has four assumptions: linearity, uncorrelated errors, homoscedasticity, and normal errors. Our exploratory analysis suggests that after the log transformation, the response is roughly symmetric and close to normal, which supports the normality assumption. Moreover, because our focus is model fit and overall explanatory power rather than precise inference on individual coefficients, mild departures from normality are less concerning.

Residual diagnostics do not show strong systematic patterns, and the spread of residuals is fairly stable across fitted values, suggesting that the linearity and homoscedasticity assumptions are at least approximately reasonable. One potential issue is multicollinearity--using many indicator variables for high-cardinality categorical predictors such as Genre and Distributor, can introduce strong correlations among predictors and make individual coefficient estimates unstable. Since our primary goal is the overall performance rather than interpreting specific coefficients, we treat this as a secondary concern.

On the other hand, the bimodal shape of the log-transformed response suggests the sample may reflect two latent groups. This motivates the use of mixture models. Accordingly, we also apply a Gaussian mixture model (GMM) to partition films into two components, and then fit separate linear regression models within each component to allow the relationships between predictors and ticket sales to differ across groups.

# Results
The linear regression on the log scale achieves an in-sample $R^2$ of about $0.68$ and a root mean squared error (RMSE) of approximately $0.82$ in log${10}$ units. Thus, while the model explains substantially more variation than the unlogged version (which had $R^2 \approx 0.35$), there is still considerable unexplained heterogeneity in box office performance.

The coefficient estimates suggest that distributor and genre are among the strongest predictors of log ticket sales. Large studio distributors such as Walt Disney, Universal, 20th Century Fox, and Warner Bros. are associated with substantially higher expected log ticket sales than the baseline distributor, conditional on the other covariates. Many smaller distributors, in contrast, are associated with lower expected sales, consistent with the idea that well-known distributors have greater reach and marketing capacity. Across genres, Adventure and Action are associated with higher ticket sales relative to the reference genre, whereas Documentary and Drama are associated with lower sales. MPAA ratings also show a pattern that PG and PG-13 films tend to have higher expected ticket sales than the baseline rating, while Not Rated and G films are associated with lower sales. However, since the majority of films in the dataset are Not Rated, this estimate may be a result of differences in representation across rating categories rather than an actual effect. Finally, the simple title indicators (whether the title contains “man”, “love”, or “life”) have small coefficients and do not materially improve model fit.

Overall, the log-transformed model captures broad, interpretable associations between basic metadata and demand.


| Predictor                     | Estimate | Std Error | p-value |
| ----------------------------- | -------: | ---------: | ------: |
| Genre = Adventure             | 0.097  |  0.072      |  0.178 |
| Distributor = 20th Century Fox |   2.835 |     0.862     | 5.9e-09 |
| MPAA = T.PG-13               |    0.395 |      0.092 | 1.7e-05 |
| Genre = Documentary       |   -0.233 |      0.061  |   0.000 |
| T.Universal    |    3.062 |      0.862  |  0.000 |


In terms of the mixture regression, we fit a two-component Gaussian mixture model to the log-transformed ticket sales to split the data into two groups, as suggested by the bimodality of response.  yielding a “low–box-office” group (component 1, $n = 4{,}484$) and a “high–box-office” group (component 0, $n = 2{,}196$). 

We then fit separate linear regression models within each component. The resulting in-sample fit is weaker than the single pooled regression. The component-wise $R^2$ values drop to approximately 0.38 and 0.52. A likely explanation is that splitting the data reduces the effective sample size within each group while retaining a large number of indicator predictors, leading to noisier and less stable estimates. Overall, this mixture-based strategy does not substantially improve our ability to explain variation in ticket sales using the limited feature set.

That said, the component-specific regressions recover broadly similar qualitative patterns. Action and Adventure genres and major studio distributors are associated with higher log ticket sales, whereas more niche genres and non-major distributors tend to be associated with lower sales, conditional on the remaining covariates.

High Box Office Group (Component 0):

| Predictor                            | Estimate | Std Error | p value |
| ------------------------------------ | -------- | --------- |--------|
| Distributor = Sony Pictures Classics | -0.859   |0.062      |  0.000 |
| Distributor = Roadside Attractions   | -0.8956  | 0.094     |  0.000 |
| Distributor = Paramount Pictures     | 0.0453   | 0.053     |  0.393 |
| MPAA = PG                            | 0.154    |  0.065    |  0.018 |
| Genre = Drama                        | -0.3106  | 0.040     |  0.000 |

Low Box Office Group Coefficients(Component 1):

| Predictor        | Estimate | Std Error |  p value |
| ---------------- | -------- | --------- | --------|
| Distributor = 20th Century Fox |0.6007  |   0.707  |      0.396|
| Genre =  Adventure | 0.1209 | 0.101 | 0.232  |
| MPAA = Not Rated |-0.3786  | 0.120  |-  0.002|
| Distributor = Walt Disney |0.5205 | 0.705 | 0.460|
| Genre = Drama | 0.1609  |  0.066   |   0.015|


# Discussion

## Summary of analysis
This report answers the question of how much of a movie’s box office performance can be explained using simplistic model and easily obtained data. We explored the dataset containing 6,897 major releases from 2006–2015, and based on the exploratory data analysis, we decided that a linear regression model would be be an appropriate simple model for modelling number of tickets sold. We modeled log-transformed ticket sales as a function of release year and month, distributor, genre, MPAA rating, and a small set of title indicators. After the first simple model, based on the observation that our response variable was bi-modal, we fit a two-component Gaussian mixture model to the log-tickets to identify the two potential underlying groups. Regression model was then fit to each compoenent to see whether relationships between predictors and outcomes differ in the low- and high-grossing segments and whether explanatory power of the model can be improved by grouping.

## key Findings
We discovered that we are able to explain a moderate amount of variation in box office performance using only basic metadata. The linear regression on the log scale attains an $R^2$ of 0.68, which was non-trivial. It can be used as a proxy for understanding broad patterns in what movie attributes contribute to the its box office performance, when computation power is limited or precise outcomes were not required. Indeed, we were able to learn from our simple models that films released by large studio distributors and in commericial genres like advanture movies systematically sell more tickets than those from smaller distributors and narrower genres. People tend to favour movies that are relatively shallow, compared to genres like documentary and drama, which are associated with lower sales. This confirms the intuitive idea that institutional backing and genre positioning matter for commercial success, and the effect is visible even when we restrict attention to a small set of coarse variables. Although we initially believe that audience could be attracted to movies with certain key words in the title, our results show that these title indicators have minimal effects on ticket sales. So we are able to make some useful inferences about movie box office performance using only minimal information and simple models.

Moreover, the mixture analysis shows that the movie market can be effectively partitioned into at least two groups: a large group of low- to moderate-grossing films and a smaller group of high-grossing films. The two-component Gaussian mixture on fits substantially better than a single Normal distribution, with one component centered around a few thousand tickets and another around millions of tickets. When we fit separate regressions within these groups, we see that basic metadata are more informative among films that have high box office, compared to those with lower ticket sales. The high group regression has higher $R^2$ and cleaner, more stable effects for distributors and genres, while the low group shows weaker fits and more residual variability. This suggests that once a film reaches the commercial “upper tier”, its performance is more systematically tied to structural choices like genre and distribution, whereas performance in the lower tier is more idiosyncratic and less predictable from simple attributes. This also suggests that future work could build on mixture frameworks to better capture the characteristics of different movies, thereby better explaining and predicting box office outcomes.

## Limitations and future work
However, it is important to recognize that there are several important limitations in our analysis. Substantively, the dataset is observational and restricted to major movies released from 2006 to 2015. This is ten years from now and trends in audience preference could change, the market could become more volatile and harder to explain with simple features and models. Being restricted to major movies would impact the generalization to smaller independent releases. Measurement could be imperfect in the dataset as assignments of genre and MPAA could be coarse and merging heterogeneous content. Methodologically, our models had issues in mutlicollinearity due to the large number of dummy variables for categorical predictors with many levels, which could lead to unstable coefficient estimates. Linearity assumption does not hold perfectly despite the transformation of the response variable, potentially leading to biased coefficients. We also did not consider interaction effects between predictors, due to the already existing multi-collinearity which we did not want to exacerbate. Finally, the mixture regressions rely on hard assignment of movies to latent components and do not carry mixture uncertainty into the regression stage, which could lead to unwanted bias.

The analysis here is a first step rather than a complete model of box office performance. If we wish to continue down this path of using minimal information and simple models, we would need to develop methods that can better extract signals from limited data. This is an active researsch area and there are many potential directions. But if we just want to improve box office explanation and prediction more generally, richer data and more sophisticated models would be helpful. Future work can extend the feature set by incorporating production budgets, sequel and franchise indicators, star metrics, and measures of pre- and post-release attention such as critic scores, online ratings and social media activity. With richer covariates, it would be natural to compare regularised linear models, tree-based methods and hierarchical models that allow distributor and genre effects to vary across time or markets. On the mixture side, a more formal finite mixture of regressions—where both component membership and regression parameters are estimated jointly—would provide a principled framework for studying regime-specific relationships, at the cost of more complex computation. Finally, a deeper treatment of selection and measurement would clarify how much of the remaining unexplained variation is due to genuinely unobserved drivers versus noise in the observed data.

\newpage

\appendix

# Appendix {-}

# Additional data details
Here are a few additional plots to further illutrate the data.

::: {#fig-top-bottom layout-ncol=2}

![](images/dist_with_most_movies.png)

![](images/age_restriction.png)

Distributors with the most movies and MPAA age restrictions overview of movies contained in the dataset.
:::

# Model details {#sec-model-details}
On top of the two models considered in the main text, we also consider the following two specifications as part of exploration. \subsection*{Ordinary linear regression on raw ticket sales}

Let $i = 1,\dots,n$ index movies and define the outcome as the number of
tickets sold,
$$
Y_i = \text{Tickets.Sold}_i.
$$
For each movie $i$, we observe:

\begin{itemize}
  \item $\text{Year}_i$: release year,
  \item $\text{Month}_i$: release month $(1,\dots,12)$,
  \item $G_i$: genre (categorical),
  \item $D_i$: distributor (categorical),
  \item $M_i$: MPAA rating (categorical),
  \item $z_{i,\text{man}}, z_{i,\text{love}}, z_{i,\text{life}} \in \{0,1\}$:
        indicator variables for whether the title contains the words
        ``man'', ``love'', or ``life''.
\end{itemize}

We treat $G_i$, $D_i$, and $M_i$ as categorical variables and represent
them with dummy variables. The linear regression model on the original
ticket scale is
\begin{align*}
Y_i
&= \beta_0
 + \beta_{\text{year}} \,\text{Year}_i
 + \beta_{\text{month}} \,\text{Month}_i \\
&\quad
 + \sum_{g} \gamma_g \,\mathbb{1}\{G_i = g\}
 + \sum_{d} \delta_d \,\mathbb{1}\{D_i = d\}
 + \sum_{m} \eta_m \,\mathbb{1}\{M_i = m\} \\
&\quad
 + \alpha_{\text{man}} z_{i,\text{man}}
 + \alpha_{\text{love}} z_{i,\text{love}}
 + \alpha_{\text{life}} z_{i,\text{life}}
 + \varepsilon_i,
\end{align*}
where one level of each factor (genre, distributor, MPAA) is taken as
the reference category, and the error terms satisfy
$$
\varepsilon_i \sim \mathcal{N}(0,\sigma^2),
\qquad i=1,\dots,n.
$$
The parameter vector
$(\beta_0, \beta_{\text{year}}, \beta_{\text{month}},
 \{\gamma_g\}_g,\{\delta_d\}_d,\{\eta_m\}_m,
 \alpha_{\text{man}},\alpha_{\text{love}},\alpha_{\text{life}})$
is estimated by ordinary least squares, i.e.\ by minimizing the sum of
squared residuals
$$
\sum_{i=1}^n \bigl(Y_i - \hat{Y}_i\bigr)^2.
$$


\subsection*{Lasso regression on log-transformed ticket sales}

For the penalised model, we work with a log-transformed outcome
$$Y_i = \log_{10}\bigl(\text{Tickets.Sold}_i\bigr)$$
using the same underlying predictors (release year, release month,
distributor, genre, MPAA rating, and title indicators).

Let $\mathbf{x}_i \in \mathbb{R}^p$ denote the design vector for movie
$i$ after preprocessing, where:

\begin{itemize}
  \item continuous predictors (such as year and month, and the binary
        title indicators) have been centered and scaled, and
  \item categorical predictors (distributor, genre, MPAA) have been
        expanded into dummy variables via one-hot encoding, with one
        reference level dropped for each factor.
\end{itemize}

The Lasso model assumes the linear relationship

$$
Y_i = \mathbf{x}_i^\top \boldsymbol{\beta} + \varepsilon_i,
\qquad i=1,\dots,n,
$$
with mean-zero errors $\varepsilon_i$, but estimates
$\boldsymbol{\beta} \in \mathbb{R}^p$ by solving the penalised least
squares problem
$$
\hat{\boldsymbol{\beta}}_{\lambda}
= \arg\min_{\boldsymbol{\beta}}
\left\{
  \frac{1}{2n}\sum_{i=1}^n
  \bigl(Y_i - \mathbf{x}_i^\top \boldsymbol{\beta}\bigr)^2
  + \lambda \sum_{j=1}^p |\beta_j|
\right\},
$$

where $\lambda \ge 0$ is a tuning parameter controlling the strength of
the $\ell_1$ penalty. The penalty is applied to the slope coefficients
$\beta_j$ (the intercept is left unpenalised or absorbed by centering).
In practice, we select $\lambda$ by $K$-fold cross-validation and use
$\hat{\boldsymbol{\beta}}_{\hat{\lambda}}$ as the final model. The
$\ell_1$ penalty both shrinks coefficients toward zero and sets many
exactly to zero, performing variable selection and mitigating the impact
of multicollinearity among the large set of dummy variables.


## Diagnostics
::: {#fig-top-bottom layout-ncol=2}

![](images/residuals_reg.png)

![](images/qq_reg.png)

Diagnostic plots for linear regression model residuals. As mentioned in main text, there seems to be
:::


\newpage


# References
We use Python and several open-source packages for our analysis [@python; @harris2020numpy; @mckinney2010pandas; @pedregosa2011scikit; @seabold2010statsmodels]